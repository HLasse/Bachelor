---
title: "Bachelor"
author: "Lasse Hansen"
date: "October 23, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#working directory and packages
```{r}
setwd("~/Desktop/Bachelor/Autobiographic/")
p_load(stringr, beepr, groupdata2, glmnet, brms, caret, kernlab, klaR, tidyverse, knitr, pROC, randomForest, xgboost)
```


##Function to load and add a column for filename
```{r}
trimload <- function(file){
  df <- data.table::fread(file)
  df$filename <- as.character(file)
  return(df)
}
```

#loading data
```{r}
folders <- list.files(pattern = '*16khz')
folderSliced <- list.files(folders, pattern = 'sliced', full.names =T)

cont <- list.files(folderSliced[1], pattern = '*.csv', full.names = T)
dp1 <- list.files(folderSliced[2], pattern = '*.csv', full.names = T)
dp2 <- list.files(folderSliced[3], pattern = '*.csv', full.names = T)


contDf <- lapply(cont, trimload) %>%
  bind_rows(.); beep(4)

dp1Df <- lapply(dp1, trimload) %>%
  bind_rows(); beep(4)

dp2Df <- lapply(dp2, trimload) %>%
  bind_rows(); beep(4)

```

##Preprocessing function
```{r Preprocessing}
preproz <- function(df){
#defining voice activity as VAD being > 0.6. Adding binary column with voice 1 and no voice 0 
df$voice <- ifelse(df$VAD > 0.5, 1, 0)
#Since each file is split in several files, we create a single id column, containing only the original file name
df$id <- substr(df$filename, 18, 24) %>% str_remove_all("_")


# 30 seconds = 3000 rows (1 row = 10 ms )
#adding 30 second groups (in column called .groups)
df <- df %>%
  group_by(id) %>%
  #creates a group column containing 3000 rows (ie. 30 secs)
  #if there are not enough data points to fill up a group, the remaining data is discarded
  do(groupdata2::group(., n=  3000, method = "greedy", force_equal = T)) %>% 
  # Convert .subgroups to an integer and then to a factor
  mutate(.groups = as.integer(.groups),
         .groups = as.factor(.groups))

##########################  PAUSES ###################################

#creating df with only the pauses. A column called consec is added which counts the number of consecutive value in voice.
#data points with no voice activity are discarded
pauseDf <- df %>% 
  dplyr::select(time, id, voice, .groups) %>%  
  group_by(id, .groups) %>%
  mutate(consec = sequence(rle(as.character(voice))$lengths)) %>%
  filter(voice == 0 )

#finding the beginning of a new pause (discarding the first value since its row 1)
flag_one <- which(pauseDf$consec == 1)[-1]
#substracting 1 to find the pause length
one_before <- flag_one - 1
#creating df with the pause lengths 
pauseDf <- pauseDf[one_before,]
#if there is less than 300 ms or more than 10 seconds before next voice activity it is not considered a pause
pauseDf <- pauseDf %>%
  filter(consec > 30 & consec < 1000)

#summarising pauses to mean length, sd of length and number of pauses
sumPauseDf <- pauseDf %>% 
  group_by(id, .groups) %>% 
  summarise(meanPauseLength = mean(consec), medianPauseLength = median(consec), sdPauseLength = sd(consec), iqrPauseLength = IQR(consec), nPauses = n())

##########################  SUMMARISING FEATURES ###################################

#removing features which could not be extracted
remove <- c("HMPDM_0", "HMPDM_1", "HMPDM_2", "HMPDM_3", "HMPDM_4", "HMPDM_5", "HMPDM_6", "HMPDM_7", "HMPDM_8", "HMPDM_9", "vowelSpace")
df[, remove] <- NULL

#removing columns without voice activity and summarising with median and iqr (sd, others???)
sumdf <- df %>% 
  filter(voice == 1) %>%
  group_by(id, .groups) %>% 
  summarise_at(.vars = names(.)[2:70],
               .funs = c(median="median", IQR = "IQR"))

#merging pauses and features
mergedDf <- merge(sumPauseDf, sumdf, by = c("id", ".groups"))

return(mergedDf)
}


```


#arrange vars function
```{r arrange vars function}
##arrange df vars by position
##'vars' must be a named vector, e.g. c("var.name"=1)
arrange.vars <- function(data, vars){
    ##stop if not a data.frame (but should work for matrices as well)
    stopifnot(is.data.frame(data))

    ##sort out inputs
    data.nms <- names(data)
    var.nr <- length(data.nms)
    var.nms <- names(vars)
    var.pos <- vars
    ##sanity checks
    stopifnot( !any(duplicated(var.nms)), 
               !any(duplicated(var.pos)) )
    stopifnot( is.character(var.nms), 
               is.numeric(var.pos) )
    stopifnot( all(var.nms %in% data.nms) )
    stopifnot( all(var.pos > 0), 
               all(var.pos <= var.nr) )

    ##prepare output
    out.vec <- character(var.nr)
    out.vec[var.pos] <- var.nms
    out.vec[-var.pos] <- data.nms[ !(data.nms %in% var.nms) ]
    stopifnot( length(out.vec)==var.nr )

    ##re-arrange vars by position
    data <- data[ , out.vec]
    return(data)
}
```

## preprocessing
```{r}
sumContDf <- preproz(contDf); beep(2)
#write.csv(sumContDf, "sumControls_2.csv")

sumDp1Df <- preproz(dp1Df); beep(1)
#write.csv(sumDp1Df, 'sumDp1_2.csv')

sumDp2Df <- preproz(dp2Df)
#write.csv(sumDp2Df, 'sumDp2_2.csv')

sumContDf <- read.csv('sumControls_2.csv')
sumContDf$X <- NULL
sumDp1Df <- read.csv('sumDp1_2.csv')
sumDp1Df$X <- NULL


df <- rbind(sumContDf, sumDp1Df, sumDp2Df)
write.csv(df, 'combSumDf_2.csv', row.names = F)


####MAKE NEW COLUMN IN SUM DF WITH ID WITH NO V1/V2

df <- read.csv('combSumDf_2.csv')

#loading and merges with clinical and demographical data
demoData <- read.csv("/home/lasse/Desktop/Bachelor/DemClinicalData.csv", sep = ";")
#removing the chronic depression patients
demoData <- demoData %>%
  filter(Diagnosis2 != "ChronicDepression")
#creating new column
demoData$temp <- ifelse(demoData$Diagnosis == "Control", "dc", "dp")
demoData$mergeID <- paste0(demoData$temp, demoData$ID)

#creating new column to merge clinical features
df$mergeID <- str_sub(df$id, end=-3)


## NO DEMO DATA FOR DC44 AND DP4 
# adding their known values to demodata
missing <- data.frame(ID = c(4, 44), Diagnosis = c('Depression', 'Control'), Gender = c('f', 'f'),
                      Remission = c(0, NA), mergeID = c('dp4', 'dc44'))

demoData <- bind_rows(demoData, missing)

#NO REMISSION DATA FOR DP25, DP29, DP12. ADDING MANUALLY
#dp25, dp29, dp12
demoData$Remission<- ifelse(demoData$mergeID == 'dp25' | demoData$mergeID == 'dp29' | demoData$mergeID == 'dp12',
                            0, demoData$Remission)


mergeDf <- merge(df, demoData, by = 'mergeID')

write.csv(mergeDf, 'fullSumDf_2.csv', row.names = F)

# noScale <- read.csv('fullSumDf_2.csv')
# noScale$visit <- str_sub(noScale$id, start= -2)
# dep1 <- noScale %>%
#   filter(Diagnosis == 'Depression' & visit == 'v1')
# 
# dep2 <- noScale %>%
#   filter(Diagnosis == 'Depression' & visit == 'v2')
# 
# cont <- noScale %>%
#   filter(Diagnosis == 'Control')
# 
# 
# summary(cont[,142:146])
# summary(dep1[,142:146])
# summary(dep2[,142:146])

#scaling variables at dataset level 
mergeDf <- mergeDf %>%
  mutate_at(.vars = names(.)[4:146],
            .funs = scale)

write.csv(mergeDf, 'ScaleSumDf.csv', row.names = F)




############################# CREATING SUBSETS FOR MODELLING + TRAIN AND TEST SET ################3
mergeDf <- read.csv('ScaleSumDf.csv')


mergeDf$visit <- str_sub(mergeDf$id, start= -2)
#subsetting data to get only depression at first visit
depDf <- mergeDf %>%
  filter(Diagnosis == 'Depression' & visit == 'v1')

#depression at visit 2 = those who experienced remission
dep2Df <- mergeDf %>% 
  filter(visit == "v2")


set.seed(100)
# Split in test and training sets (use groupdata2)
depDfParts <- partition(depDf, p = 0.2, id_col = "id")

depDf_test_set <- depDfParts[[1]]
depDf_train_set <- depDfParts[[2]]

#checking amount of remission in test/training set

#see which ids in the set + remission and number of windows
depDf_test_set %>% select(Remission, id) %>% group_by(id) %>% summarize(remission = mean(Remission), n()) %>% kable()
depDf_test_set %>% select(Remission, id) %>% group_by(id) %>% summarize(remission = mean(Remission), nWindows = n()) %>%   group_by(remission) %>% summarize(sum(nWindows)) %>% kable()

depDf_train_set %>% select(Remission, id) %>% group_by(id) %>% summarize(remission = mean(Remission), n()) %>% kable()
depDf_train_set %>% select(Remission, id) %>% group_by(id) %>% summarize(remission = mean(Remission), nWindows = n()) %>%   group_by(remission) %>% summarize(sum(nWindows)) %>% kable()

#################### 
# XX REMISSION IN TOTAL - X IN TEST SET, 19 IN TRAINING   
# XX NO REMISSION IN TOTAL - X IN TEST SET, 10 IN TRAINING

# XX 30 SECONDS WINDOWS WITH REMISSION IN TEST SET - XX 30 SECONDS WINDOWS WITH NO REMISSION
# XX 30 SECOND WINDOWS WITH REMISSION IN TRAINING SET - XX 30 SECONDS WINDOWS WITH NO REMISSION

####################
# Write to files
#write.csv(depDf_test_set, "depDf_test.csv", row.names = F)
#write.csv(depDf_train_set, "depDf_train.csv", row.names = F)


#subset only for controls and dp_v1
contDepDf <- mergeDf %>%
  filter(visit == 'v1') 

contDepDf$DiagnosisInteger <- ifelse(contDepDf$Diagnosis == "Depression", 1, 0)
# Split in test and training sets (use groupdata2)
contDepParts <- partition(contDepDf, p = 0.2, id_col = "id")

contDep_test_set <- contDepParts[[1]]
contDep_train_set <- contDepParts[[2]]



#checking amount of diagnosis in test/training set
contDep_train_set %>% select(DiagnosisInteger, id) %>% group_by(id) %>% summarize(diagnosis = mean(DiagnosisInteger), count = n()) %>%   group_by(diagnosis) %>% summarize(sum(count)) %>% kable()

contDep_test_set %>% select(DiagnosisInteger, id) %>% group_by(id) %>% summarize(diagnosis = mean(DiagnosisInteger), count = n()) %>%   group_by(diagnosis) %>% summarize(sum(count)) %>% kable()


#################### 
# XX  DIAGNOSIS IN TOTAL - X IN TEST SET, 28 IN TRAINING   
# XX NO DIAGNOSIS IN TOTAL - X IN TEST SET, 16 IN TRAINING

# XX 30 SECONDS WINDOWS WITH DEPRESSION IN TEST SET - XX 30 SECONDS WINDOWS WITH NO DEPRESSION
# XX 30 SECOND WINDOWS WITH DEPRESSION IN TRAINING SET - XX 30 SECONDS WINDOWS WITH NO DEPRESSION

####################
# Write to files
#write.csv(contDep_test_set, "contDep_test.csv", row.names = F)
#write.csv(contDep_train_set, "contDep_train.csv", row.names = F)
```


Preparing the elastic net
```{r elastic net}

#################### MODEL 1 - DIAGNOSIS FROM VOICE ###############
contDep <- read.csv("contDep_train.csv")
remove <- c("Diagnosis2", "temp", "Education", "HamD6_Before", "HamD17_Before", "HamD6_After", "HamD17_After",
            "ExecutiveFunctionIED", "ExecutiveFunctionOTS", "SustainedAttention", "WorkingMemory", "VerbalMemory", "IQ", "Age")
contDep[, remove] <- NULL

contDep$Gender <- ifelse(contDep$Gender == "f", 1, 0)
contDep$Gender <- as.factor(contDep$Gender)

#changing the order of columns
contDep <- arrange.vars(contDep, c("id"=151, "mergeID"=150, ".groups"=152, "Gender" = 144))
colnames(contDep)
#creating predictor column 
xContDep <- contDep[, -c(144:152)] #change to the values in the set

#creating outcome variable
yContDep <- select(contDep, DiagnosisInteger) 
yContDep$DiagnosisInteger <- as.factor(yContDep$DiagnosisInteger)

#check for NA
identical(xContDep, xContDep[complete.cases(xContDep),])

#################### MODEL 2 - REMISSION FROM VOICE ###############
dep <- read.csv('depDf_train.csv')

dep[, remove] <- NULL

dep$Gender <- ifelse(dep$Gender == "f", 1, 0)
dep$Gender <- as.factor(dep$Gender)


#changing the order of columns
dep <- arrange.vars(dep, c("id"=151, "mergeID"=150, ".groups"=149, "Gender" = 144))
colnames(dep)


#creating predictor column 
xDep <- dep[, -c(144:151)] #change to the values in the set

#creating outcome variable
yDep <- select(dep, Remission) 
yDep$Remission <- as.factor(yDep$Remission)


#check for NA
identical(xDep, xDep[complete.cases(xDep),])
```

##Running the elastic net
```{r}
## Define predictors and outcome
xContDep <- model.matrix(~.-1, data= xContDep) 
xDep <- model.matrix(~.-1, data= xDep)


# makes outcome variables into a non data frame because glmnet doesn’t deal with dataframes
yContDep <- as.numeric(unlist(yContDep))
yDep <- as.numeric(unlist(yDep))



#function to run the elastic net. First chooses the optimal alpha (ie the split between L1 and L2 regularization), then runs the elastic net
elasticfun <- function(y, x){
  alphaslist<-seq(0,1,by=0.1)
  foldslist<-seq(4,12)
  pars=expand.grid(alphaslist,foldslist)

  cvm1=matrix(rep(0,length(alphaslist)))

  elasticnet1<-lapply(1:length(cvm1), 
                  function(a){
                    cv.glmnet(x, y, alpha=alphaslist[a], family="binomial", 
                                                         lambda.min.ratio=.001,nfolds = 5)})

  for (i in 1:length(alphaslist)) {cvm1[i]=min(elasticnet1[[i]]$cvm)}

  n1=which(cvm1==min(cvm1))

  alpha1=alphaslist[n1]

# Run cross-validated elastic net with the chosen alpha (to choose lambda)
  mod_cv <- cv.glmnet(x=x, y=y, family='binomial', alpha=alpha1, nfolds=5) # Modify family if not binomial
  coefs=as.data.frame(as.matrix(coef(mod_cv, mod_cv$lambda.1se)))
  coefs$predictors<-rownames(coefs)
  rownames(coefs) <- NULL
  names(coefs)[1] <- "betas"
  coefs=subset(coefs,betas!=0)
  coefs1=coefs[order(abs(coefs$betas)),]
  coefs1$alpha = alpha1
  return(coefs1)
}


contDepNet <- elasticfun(yContDep, xContDep)
depNet <- elasticfun(yDep, xDep)

contDepNet$betas <- round(contDepNet$betas, 4)
contDepNet
depNet$betas <- round(depNet$betas, 4)
depNet
# #saving values
save(contDepNet, file = "contDepNet.RData")
save(depNet, file = "depNet.RData")
```


## density plots
```{r}
dep %>% 
  select_if(is.numeric) %>% 
  #select(depPredictors[54:62]) %>%
  gather(metric, value) %>% 
  ggplot(aes(value, fill = metric)) + 
  geom_density(show.legend = FALSE) + 
  facet_wrap(~ metric, scales = "free")

dep %>% 
  select(depPredictors) %>% 
  #select(depPredictors[54:62]) %>%
  gather(metric, value) %>% 
  ggplot(aes(value, fill = metric)) + 
  geom_density(show.legend = FALSE) + 
  facet_wrap(~ metric, scales = "free")


##also make for contDep
```

#downsampling remission data, creating folds for cv and creating control statements for caret's train function
```{r}
load('depNet.RData')

#keeping variables with a beta > abs(0.1) in order to take inter-variable correlations into account
preds <- depNet %>% 
  filter(abs(betas) > 0.1)
depPredictors <- preds$predictors

#removing intercept 
depPredictors <- depPredictors[-length(depPredictors)]

#creating dataframe for models taking formula inputs (like brms)
depFormula <- dep %>%
  dplyr::select(depPredictors, Remission, id)


dep$Remission <- as.factor(dep$Remission)
dep$nPauses <- as.numeric(dep$nPauses)
levels(dep$Remission) <- c("NoRemission", "Remission")


###Downsampling data to have an even number of ids for remission/noRemission
#depDown <- groupdata2::balance(dep, size="min", cat_col = "Remission", 
#       id_col = "id", id_method = "n_ids")
#write.csv(depDown, 'depDown.csv', row.names = F)
depDown <- read.csv('depDown.csv')

dep %>%
  count(Remission, id) %>%
  kable()

depDown %>% 
  count(Remission, id) %>% 
  kable()
#8 id in each group

#creating folds to use for the index argument in trainControl which respect the groupings in the data
#ie no ids are present in 2 groups
depDownTrainFold <- groupKFold(depDown$id, k = 4) #16 different ids, doing a 4-fold cv (since 16/4 is a nice even 4)
depTrainFold <- groupKFold(dep$id, k = 7) #28 different ids, doing a 7-fold cv (since 28/7 is a nice even 4)


##Control statements for train()
## For accuracy, Kappa, the area under the ROC curve, sensitivity and specificity:
fiveStats <- function(...) c(twoClassSummary(...), 
                             defaultSummary(...))
## Everything but the area under the ROC curve:
fourStats <- function (data, lev = levels(data$obs), model = NULL) {
  accKapp <- postResample(data[, "pred"], data[, "obs"])
  out <- c(accKapp,
           sensitivity(data[, "pred"], data[, "obs"], lev[1]),
           specificity(data[, "pred"], data[, "obs"], lev[2]))
  names(out)[3:4] <- c("Sens", "Spec")
  out
}

#Two control functions are developed for situations when class probabilities can be created and when they cannot:
#(class probabilities can not be created when classes are weighted)

#controls for the downsampled df
depDownCtrl <- trainControl(method = "cv", 
                     classProbs = TRUE,
                     summaryFunction = fiveStats,
                     verboseIter = TRUE,
                     index = depDownTrainFold)

depDownCtrlNoProb <- trainControl(method = "cv", 
                     classProbs = FALSE,
                     summaryFunction = fourStats,
                     verboseIter = TRUE,
                     index = depDownTrainFold)

#controls for the full df
depCtrl <- trainControl(method = "cv", 
                     classProbs = TRUE,
                     summaryFunction = fiveStats,
                     verboseIter = TRUE,
                     index = depTrainFold)

depCtrlNoProb <- trainControl(method = "cv", 
                     classProbs = FALSE,
                     summaryFunction = fourStats,
                     verboseIter = TRUE,
                     index = depTrainFold)
```



Bayesian logistic models
```{r}

depLogistic <- brm(Remission ~.-id + (1|id), 
                    data = depFormula, family = bernoulli(), 
                    cores = 4, chains = 4, 
                    control = list(adapt_delta = .998, max_treedepth = 15))
depLogistic

save(depLogistic, file = 'depLogistic.RData')

##not finished
```


#SVM models
```{r predicting remission}
############################# LINEAR SVM ¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤
set.seed(60)


#grid search for optimal cost parameter
grid <- expand.grid(C = 2^(seq(-4,4)))


### Linear svm no class weights
#full training set
svmDepLinNoWeights <- train(x = dep[,depPredictors], y = dep$Remission,
                    method = "svmLinear",
                    metric = "ROC",
                    trControl=depCtrl,
                    tuneGrid = grid)

svmDepLinNoWeights
save(svmDepLinNoWeights, file = 'svmDepLinNoWeights.RData')

#downsampled
svmDepDownLinNoWeights <- train(x = depDown[,depPredictors], y = depDown$Remission,
                    method = "svmLinear",
                    metric = "ROC",
                    trControl=depDownCtrl,
                    tuneGrid = grid)


svmDepDownLinNoWeights
save(svmDepDownLinNoWeights, file = 'svmDepDownLinNoWeights.RData')


### Linear svm with class weights
#full training data
svmDepLinWeighted <- train(x = dep[,depPredictors], y = dep$Remission,
                    method = "svmLinear",
                    metric = "Kappa",
                    trControl=depCtrlNoProb,
                    tuneGrid = grid,
                    class.weights = c(NoRemission = 1, Remission = 5)) #5 times as costly to choose remission

svmDepLinWeighted
save(svmDepLinWeighted, file = 'svmDepLinWeighted.RData')

#downsampled
svmDepDownLinWeighted <- train(x = depDown[,depPredictors], y = depDown$Remission,
                    method = "svmLinear",
                    metric = "Kappa",
                    trControl=depDownCtrlNoProb,
                    tuneGrid = grid,
                    class.weights = c(NoRemission = 1, Remission = 5))

svmDepDownLinWeighted
save(svmDepDownLinWeighted, file = 'svmDepDownLinWeighted.RData')


############################# RBF SVM ¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤
#finding optimal sigma and cost parameters
sigmaRange <- sigest(as.matrix(dep[,depPredictors]))
svmRGrid2 <- expand.grid(.sigma = sigmaRange, .C = 2^(seq(-4, 4)))
#### no class weights
#full training set
svmDepRbfNoWeights <- train(dep[,depPredictors], dep$Remission, 
                   method = "svmRadial", 
                   metric = "ROC", 
                   tuneGrid = svmRGrid2, 
                   trControl = depCtrl)
svmDepRbfNoWeights
save(svmDepRbfNoWeights, file = 'svmDepRbfNoWeights.RData')


#downsampled
svmDepDownRbfNoWeights <- train(depDown[,depPredictors], depDown$Remission, 
                   method = "svmRadial", 
                   metric = "ROC", 
                   tuneGrid = svmRGrid2, 
                   trControl = depDownCtrl)
svmDepDownRbfNoWeights
save(svmDepDownRbfNoWeights, file = 'svmDepDownRbfNoWeights.RData')


#### with class weights
svmDepRbfWeighted <- train(dep[,depPredictors], dep$Remission, 
                   method = "svmRadial", 
                   metric = "Kappa", 
                   tuneGrid = svmRGrid2, 
                   trControl = depCtrlNoProb,
                   class.weights = c(NoRemission = 1, Remission = 5))
svmDepRbfWeighted
save(svmDepRbfWeighted, file = 'svmDepRbfWeighted.RData')

svmDepDownRbfWeighted <- train(depDown[,depPredictors], depDown$Remission, 
                   method = "svmRadial", 
                   metric = "Kappa", 
                   tuneGrid = svmRGrid2, 
                   trControl = depDownCtrlNoProb,
                   class.weights = c(NoRemission = 1, Remission = 5))
svmDepDownRbfWeighted
save(svmDepDownRbfWeighted, file = 'svmDepDownRbfWeighted.RData')


###########################WORK IN PROGRESS ###########################
## see how many id were predicted correctly / the predicted probability of remission
linTest <- depTest %>%
  select(id, PredictionsLinear, PredictionsRbf, Remission) 

linTest$PredictionsLinear = as.numeric(ifelse(linTest$PredictionsLinear == "NoRemission", 0, 1))
linTest$PredictionsRbf = as.numeric(ifelse(linTest$PredictionsRbf == "NoRemission", 0, 1))
linTest$Remission = as.numeric(ifelse(linTest$Remission == "NoRemission", 0, 1))

sumLin <- linTest %>%
  group_by(id) %>%
  summarise(LinearProb = mean(PredictionsLinear), RbfProb = mean(PredictionsRbf), Remission = mean(Remission))
#pretty bad....

##better probabilities:
depTest$PredictionsRbf <- predict(svmRModel, newdata = depTest[,depPredictors], type = 'prob')$Remission
depTest$PredictionsLinear <- predict(svm_Linear, newdata = depTest[,depPredictors], type = 'prob')$Remission



probRemission <- depTest %>%
  select(id, PredictionsLinear, PredictionsRbf, Remission)
probRemission$Remission = as.numeric(ifelse(probRemission$Remission == "NoRemission", 0, 1))

sumProb <- probRemission %>%
  group_by(id) %>%
  summarise(LinearProb = mean(PredictionsLinear), RbfProb = mean(PredictionsRbf), Remission = mean(Remission))


sumProb


###AUC and stuff
#can only create ROC curves for unweighted since the weighted models can only classify
evalResults <- data.frame(Remission = depTest$Remission)
evalResults$SVMLinNoWeights <- predict(svmLinNoWeights, newdata = depTest[,depPredictors], type = 'prob')[,1]
evalResults$SVMRbfNoWeights <- predict(svmRbfNoWeights, newdata = depTest[,depPredictors], type = 'prob')[,1]

#calculating AUC and creating ROC curves
SVMLinNoWeightsROC <- roc(evalResults$Remission, evalResults$SVMLinNoWeights, levels = rev(levels(evalResults$Remission)))
SVMLinNoWeightsROC

SVMRbfNoWeightsROC <- roc(evalResults$Remission, evalResults$SVMRbfNoWeights, levels = rev(levels(evalResults$Remission)))
SVMRbfNoWeightsROC

#To plot the curves:
par(pty="s")
plot(SVMLinNoWeightsROC, legacy.axes = TRUE, col = 'black')
plot(SVMRbfNoWeightsROC, legacy.axes = TRUE, add = T, col = 'red')


#trying to find optimal decision threshold (based on AUC)
SVMLinThresh <- coords(SVMLinNoWeightsROC, x = "best", best.method = "closest.topleft")
SVMLinThresh

SVMRbfThresh <- coords(SVMRbfNoWeightsROC, x = "best", best.method = "closest.topleft")
SVMRbfThresh

#using the newly calculated thresholds to classify 
evalResults$SVMLinNoWeightsPred <- factor(ifelse(evalResults$SVMLinNoWeights < SVMLinThresh[1], "Remission", "NoRemission"), levels = levels(evalResults$Remission))

evalResults$SVMRbfNoWeightsPred <- factor(ifelse(evalResults$SVMRbfNoWeights < SVMRbfThresh[1], "Remission", "NoRemission"), levels = levels(evalResults$Remission))


#confusion matrices with new thresholds
confusionMatrix(data = evalResults$SVMLinNoWeightsPred, reference = evalResults$Remission, positive = "Remission")

confusionMatrix(data = evalResults$SVMLinWeighted, reference = evalResults$Remission, positive = "Remission")

confusionMatrix(data = evalResults$SVMRbfNoWeightsPred, reference = evalResults$Remission, positive = "Remission")

confusionMatrix(data = evalResults$SVMRbfWeighted, reference = evalResults$Remission, positive = "Remission")

#### ^^ TRAIN THRESHOLD ON TRAIN DATA INSTEAD
```


#Random forest
```{r}
#full training set
depRf <- train(x = dep[,depPredictors], y = dep$Remission,
                    method = "rf",
                    metric = "ROC",
                    trControl=depCtrl)
depRf #everything is remission
save(depRf,  file = 'depRf.RData')

#downsampled
depDownRf <- train(x = depDown[,depPredictors], y = depDown$Remission,
                    method = "rf",
                    metric = "ROC",
                    trControl=depDownCtrl)
depDownRf
save(depDownRf, file =  'depDownRf.RData')
#better, but still bad..

```


#XGboost
```{r}

#### work in progress 

#following this tutorial: https://www.kaggle.com/pelkoja/visual-xgboost-tuning-with-caret

# #tuneable parameters:
#     nrounds: Number of trees, default: 100
#     max_depth: Maximum tree depth, default: 6
#     eta: Learning rate, default: 0.3
#     gamma: Used for tuning of Regularization, default: 0
#     colsample_bytree: Column sampling, default: 1
#     min_child_weight: Minimum leaf weight, default: 1
#     subsample: Row sampling, default: 1

#### Fitting baseline xgboost with default parameters
grid_default <- expand.grid(
  nrounds = 100,
  max_depth = 6,
  eta = 0.3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

train_control <- caret::trainControl(
  method = "none",
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgbBase <- train(x = dep[,depPredictors], y = dep$Remission,
                 trControl = ctrl,
                 tuneGrid = grid_default,
                 method = "xgbTree",
                 verbose = TRUE
)

xgbBase

############TUNING PARAMETERS
# start nrounds from 200, as smaller learning rates result in errors so large with lower starting points that they'll mess the scales
tune_grid <- expand.grid(
  nrounds = seq(from = 200, to = 1000, by = 50), #max treedepth 1000 to get a reasonable running time while testing hyperparameter combinations
  eta = c(0.025, 0.05, 0.1, 0.3), #rule of thumb [2-10]/#trees
  max_depth = c(2, 3, 4, 5, 6),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

tune_control <-trainControl(
  method = "cv", # cross-validation
  number = 3, # with n folds 
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgbTune <- train(x = dep[,depPredictors], y = dep$Remission,
                 trControl = tune_control,
                 tuneGrid = tune_grid,
                 method = "xgbTree",
                 verbose = TRUE
)

xgbTune

# helper function to plot results
tuneplot <- function(x, probs = .90) {
  ggplot(x) +
    coord_cartesian(ylim = c(quantile(x$results$Accuracy, probs = probs), min(x$results$Accuracy))) +
    theme_bw()
}
tuneplot(xgbTune)
xgbTune$bestTune

##with 1000 iterations an eta (learning rate) of 0.3 seems to be a good starting point, though they are all very close 

###Finding optimal max_depth and min_child_weight
#fixing the learning rate to 0.3 setting maximum depth to 2 (best from previous model) to 4 to experiment a bit around the suggested best tune in previous step. Then, well fix maximum depth and minimum child weight:

tune_grid2 <- expand.grid(
  nrounds = seq(from = 50, to = 1000, by = 50),
  eta = xgbTune$bestTune$eta,
  max_depth = c(xgbTune$bestTune$max_depth:4),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1, 2, 3),
  subsample = 1
)

xgbTune2 <- train(x = dep[,depPredictors], y = dep$Remission,
  trControl = tune_control,
  tuneGrid = tune_grid2,
  method = "xgbTree",
  verbose = TRUE
)
xgbTune2
tuneplot(xgbTune2)
xgbTune2$bestTune

####Tuning row and column sampling
tune_grid3 <- expand.grid(
  nrounds = seq(from = 50, to = 1000, by = 50),
  eta = xgbTune$bestTune$eta, #still 0.3
  max_depth = xgbTune2$bestTune$max_depth,  #found to be 4
  gamma = 0,
  colsample_bytree = c(0.4, 0.6, 0.8, 1.0),
  min_child_weight = xgbTune2$bestTune$min_child_weight, #found to be 1
  subsample = c(0.5, 0.75, 1.0)
)

xgbTune3 <- train(x = dep[,depPredictors], y = dep$Remission,
  trControl = tune_control,
  tuneGrid = tune_grid3,
  method = "xgbTree",
  verbose = TRUE
)

tuneplot(xgbTune3, probs = .95)
xgbTune3$bestTune

####Tuning gamma
tune_grid4 <- expand.grid(
  nrounds = seq(from = 50, to = 1000, by = 50),
  eta = xgbTune$bestTune$eta,
  max_depth = xgbTune2$bestTune$max_depth,
  gamma = c(0, 0.05, 0.1, 0.5, 0.7, 0.9, 1.0), #trying different gamma values
  colsample_bytree = xgbTune3$bestTune$colsample_bytree,
  min_child_weight = xgbTune2$bestTune$min_child_weight,
  subsample = xgbTune3$bestTune$subsample
)

xgbTune4 <-train(x = dep[,depPredictors], y = dep$Remission,
  trControl = tune_control,
  tuneGrid = tune_grid4,
  method = "xgbTree",
  verbose = TRUE
)

tuneplot(xgbTune4)
xgbTune4$bestTune

#Reducing learning rate (eta)  to find the final model
tune_grid5 <- expand.grid(
  nrounds = seq(from = 100, to = 10000, by = 100), #upping treedepth to 10000
  eta = c(0.01, 0.015, 0.025, 0.05, 0.1),
  max_depth = xgbTune2$bestTune$max_depth,
  gamma = xgbTune4$bestTune$gamma,
  colsample_bytree = xgbTune3$bestTune$colsample_bytree,
  min_child_weight = xgbTune2$bestTune$min_child_weight,
  subsample = xgbTune3$bestTune$subsample
)

xgbTune5 <- train(x = dep[,depPredictors], y = dep$Remission,
  trControl = tune_control,
  tuneGrid = tune_grid5,
  method = "xgbTree",
  verbose = TRUE
)

tuneplot(xgbTune5)
xgbTune5$bestTune

###### Final model
final_grid <- expand.grid(
  nrounds = xgbTune5$bestTune$nrounds,
  eta = xgbTune5$bestTune$eta,
  max_depth = xgbTune5$bestTune$max_depth,
  gamma = xgbTune5$bestTune$gamma,
  colsample_bytree = xgbTune5$bestTune$colsample_bytree,
  min_child_weight = xgbTune5$bestTune$min_child_weight,
  subsample = xgbTune5$bestTune$subsample
)

xgbFit <- train(x = dep[,depPredictors], y = dep$Remission,
  trControl = train_control,
  tuneGrid = final_grid,
  method = "xgbTree",
  verbose = TRUE
)

xgbFit


############ testing performance
#### baseline xgboost with default parameters


## pretty decent!


##### default parameters were better. Probably due tothe insanely high testing accuracies making it difficult to tune

```


Naive Bayes
```{r}
#http://uc-r.github.io/naive_bayes   <- nice tutorial 
####### Predicting remission

#tuning grid
grid <- expand.grid(fL=seq(0,1, 0.1), 
                    usekernel = TRUE, 
                    adjust=seq(0,1,0.1))


#usekernel parameter allows us to use a kernel density estimate for continuous variables versus a guassian density estimate,
#adjust allows us to adjust the bandwidth of the kernel density (larger numbers mean more flexible density estimate),
#fL allows us to incorporate the Laplace smoother. (adding a small number to each of the counts in the frequencies for each feature, which ensures that each feature has a nonzero probability of occuring for each class)

#full training data
depNb <- train(x = dep[,depPredictors],y = dep$Remission,
              method = 'nb',
              trControl = depCtrl,
              prior = c(0.5, 0.5), #setting equal priors to try to deal with uneven class size
              metric = "ROC", 
              tuneGrid = grid) 
depNb$results %>% 
  top_n(5, wt = ROC) %>%
  arrange(desc(ROC))

save(depNb, file = 'depNb.RData')
#downsampled
depDownNb <- train(x = depDown[,depPredictors],y = depDown$Remission,
              method = 'nb',
              trControl = depDownCtrl,
              metric = "ROC", 
              tuneGrid = grid) 


depDownNb$results %>% 
  top_n(5, wt = ROC) %>%
  arrange(desc(ROC))

save(depDownNb, file = 'depDownNb.RData')


```

K-Nearest neighbors
```{r}
#full training set
depKnn <- train(dep[,depPredictors], dep$Remission, 
                method = "knn", 
                metric = "ROC", 
                tuneGrid = data.frame(.k = c(4*(0:5)+1, 20*(1:5)+1,50*(2:9)+1)),
                trControl = depCtrl)

depKnn
save(depKnn, file = 'depKnn.RData')

#downsampled
depDownKnn <- train(depDown[,depPredictors], depDown$Remission, 
                method = "knn", 
                metric = "ROC", 
                tuneGrid = data.frame(.k = c(4*(0:5)+1, 20*(1:5)+1,50*(2:9)+1)),
                trControl = depDownCtrl)

depDownKnn
save(depDownKnn, file = 'depDownKnn.RData')
```

Ensemble
```{r}
### TO DO
```

Predictions and performance
```{r}
############################# TESTING PERFORMANCE - REMISSION DATA #######################
################# WORK IN PROGRESS #####################
depTest <- read.csv("depDf_test.csv")


#### Recoding factor levels
depTest$Remission <- ifelse(depTest$Remission == 0, 'NoRemission', 'Remission')
depTest$Remission <- as.factor(depTest$Remission)

#making new dataframe to hold only predictions
depResults <- data.frame(Remission = depTest$Remission)

#loading models 
load('svmDepLinNoWeights.RData')
load('svmDepDownLinNoWeights.RData')
load('svmDepLinWeighted.RData')
load('svmDepDownLinWeighted.RData')

load('svmDepRbfNoWeights.RData')
load('svmDepDownRbfNoWeights.RData')
load('svmDepRbfWeighted.RData')
load('svmDepDownRbfWeighted.RData')

load('depRf.RData')
load('depDownRf.RData')

load('depNb.RData')
load('depDownNb.RData')

load('depKnn.RData')
load('depDownKnn.RData')


######### list of models
#without the weighted svm (since it doesn't make sense to calculate probabilities from the weighted models)
depModelListProps <- list(svmLin = svmDepLinNoWeights,
                     svmLinDown = svmDepDownLinNoWeights,
                     svmRbf = svmDepRbfNoWeights,
                     svmRbfDown = svmDepDownRbfNoWeights,

                     rf = depRf,
                     rfDown = depDownRf,

                     nb = depNb,
                     nbDown = depDownNb,

                     knn = depKnn,
                     knnDown = depDownKnn)
#with all models

depWeightedModels <- list(svmLinWeighted = svmDepLinWeighted,
                          svmLinDownWeighted = svmDepDownLinWeighted,
                          svmRbfWeighted = svmDepRbfWeighted,
                          svmRbfWeightedDown = svmDepDownRbfWeighted)

depModelList <- c(depModelListProps, depWeightedModels)

#adding predictions to df
predictFun <- function(model, data, type = 'prob'){
  if(type == 'prob'){
  pred <- predict(model, newdata = data, type = "prob")$Remission
  }
  if(type == 'prediction'){
  pred <- predict(model, newdata = data)
  }
  return(pred)
}

#calculating prediction probabilites
depPredictionsProb <- lapply(depModelListProps, predictFun, data = depTest[,depPredictors], type ='prob')
depPredictionsProb <- bind_rows(depPredictionsProb)

#calculating predicted class
depPredictions <- lapply(depModelList, predictFun, data = depTest[,depPredictors], type = 'prediction')
depPredictions <- bind_rows(depPredictions)


#confusion matrices
confusionMatrix(data = depPredictions$svmLin, reference = depPredictions$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$svmLinDown, reference = depPredictions$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$svmLinWeighted, reference = depPredictions$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$svmRbf, reference = depTest$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$svmRbfDown, reference = depTest$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$svmRbfWeighted, reference = depTest$Remission, positive = "Remission")

confusionMatrix(data = depPredictions$rf, reference = depTest$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$rfDown, reference = depTest$Remission, positive = "Remission")

confusionMatrix(data = depPredictions$nb, reference = depTest$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$nbDown, reference = depTest$Remission, positive = "Remission")

confusionMatrix(data = depPredictions$knn, reference = depTest$Remission, positive = "Remission")
confusionMatrix(data = depPredictions$knnDown, reference = depTest$Remission, positive = "Remission")

#auc and ROC curves
ROCFun <- function(columnName){
  rocObj <-roc(depTest$Remission, depPredictionsProb[,columnName], levels = rev(levels(depTest$Remission)))
  ciRoc <- ci(rocObj)
  return(ciRoc)
}

depPredictionsProb <- as.data.frame(depPredictionsProb)
rocs <- colnames(depPredictionsProb)

##creating ROC objects and plotting ROC curves
ROCS <- lapply(rocs, rocFun)
rocs
par(pty="s")
plot(ROCS[[1]], legacy.axes = TRUE, col = 'black') #svmLin
plot(ROCS[[2]], legacy.axes = TRUE, add = T, col = 'red') #svmLinDown
plot(ROCS[[3]], legacy.axes = TRUE, add = T, col = 'blue')   #svmRbf
plot(ROCS[[4]], legacy.axes = TRUE, add = T, col = 'orange')   #svmRbfDown
plot(ROCS[[5]], legacy.axes = TRUE, add = T, col = 'magenta')   #rf
plot(ROCS[[6]], legacy.axes = TRUE, add = T, col = 'cyan')   #rfDown
plot(ROCS[[7]], legacy.axes = TRUE, add = T, col = 'pink')   #nb
plot(ROCS[[8]], legacy.axes = TRUE, add = T, col = 'green')   #nbDown
plot(ROCS[[9]], legacy.axes = TRUE, add = T, col = 'purple')   #knn
plot(ROCS[[10]], legacy.axes = TRUE, add = T, col = 'lightblue')  #knnDown
legend("bottomright", inset = 0.02, legend = c("SvmLin", "SvmLinDown", "svmRbf", "svmRbfDown", "rf", "rfDown", "nb", "nbDown", "knn", "knnDown"), col = c("black", "red", "blue", "orange", "magenta", "cyan", "pink", "green", "purple", "lightblue"), lty = 1, cex = 0.8)
title("ROC for each algorithm", cex = 0.8, line = 2.5)

#auc
aucDf <- data.frame(lower = NA, auc = NA, upper = NA, model = rocs)
for(i in 1:length(rocs)){
  aucDf$lower[i] <- ci(ROCS[[i]])[1]
  aucDf$auc[i] <- ci(ROCS[[i]])[2]
  aucDf$upper[i] <- ci(ROCS[[i]])[3]
}
aucDf
```


